{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5AlN3phVre5"
      },
      "source": [
        "# Загрузка библиотек. Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3FAo1PUEZNC2"
      },
      "outputs": [],
      "source": [
        "# Функция для добавления заголовка \"lemma\" в CSV-файл\n",
        "def add_header_to_csv(filepath):\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.reader(f)\n",
        "        rows = list(reader)\n",
        "\n",
        "    # Перезаписываем файл, добавляя заголовок в первую строку\n",
        "    with open(filepath, 'w', encoding='utf-8', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['lemma'])  # Добавляем заголовок\n",
        "        writer.writerows(rows)      # Записываем оставшиеся строки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Заголовок добавлен: cleaned_anonymous_angelus.predicted_лем.csv\n",
            "Заголовок добавлен: cleaned_alanus_de_insula_dist_summa.predicted_лем.csv\n",
            "Заголовок добавлен: cleaned_nicolas_de_gorran_distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: cleaned_guido_ebroicensis_summa.predicted_лем.csv\n",
            "Заголовок добавлен: cleaned_petrus_cantor_distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: anonymous_angelus.predicted_лем.csv\n",
            "Заголовок добавлен: cleaned_nicolas_de_biard-distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: cleaned_mauritius_hibernicus_distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: alanus_de_insula_dist_summa.predicted_лем.csv\n",
            "Заголовок добавлен: mauritius_hibernicus_distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: nicolas_de_biard-distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: petrus_cantor_distinctiones.predicted_лем.csv\n",
            "Заголовок добавлен: guido_ebroicensis_summa.predicted_лем.csv\n",
            "Заголовок добавлен: nicolas_de_gorran_distinctiones.predicted_лем.csv\n"
          ]
        }
      ],
      "source": [
        "lemmas_folder = os.path.join(\"..\", \"data\", \"lemmas\")\n",
        "\n",
        "for filename in os.listdir(lemmas_folder):\n",
        "    if filename.endswith('.csv'):\n",
        "        filepath = os.path.join(lemmas_folder, filename)\n",
        "        add_header_to_csv(filepath)\n",
        "        print(f\"Заголовок добавлен: {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-8P-unrYO0i"
      },
      "source": [
        "# Подсчитываем 100 самых частотных слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CTB4n2mBYlPW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "lemma\n",
              "deus        490\n",
              "homo        290\n",
              "Christus    290\n",
              "dico        288\n",
              "sum         205\n",
              "debeo       140\n",
              "triplex     116\n",
              "malus       110\n",
              "dominus     108\n",
              "comparo     106\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ищем все CSV-файлы в папке с леммами\n",
        "all_files = glob.glob(os.path.join(lemmas_folder, \"*.csv\"))\n",
        "\n",
        "# Создаём пустой DataFrame для объединения\n",
        "df_merged = pd.DataFrame()\n",
        "\n",
        "# Читаем каждый CSV и добавляем его в общий DataFrame\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "    df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
        "\n",
        "# Подсчитываем частоты по леммам\n",
        "word_counts = df_merged['lemma'].value_counts()\n",
        "\n",
        "# Извлекаем 100 самых частотных лемм\n",
        "top_100_words = word_counts.head(100)\n",
        "\n",
        "top_100_words.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B3Aunok8Ynqo"
      },
      "outputs": [],
      "source": [
        "top_100_words.to_csv('../output/stats_tables/top_100_words.csv', index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VjjVHdpCqbx"
      },
      "source": [
        "# Считаем топ-слова (за один сборник каждое слово считаем не больше одного раза)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vneFyopxcLp3",
        "outputId": "c061955e-0f4d-4175-8030-86c18e8b5ea6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "lemma\n",
              "puer         14\n",
              "iudicium     14\n",
              "fons         14\n",
              "mors         14\n",
              "humilitas    14\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_merged = pd.DataFrame()\n",
        "\n",
        "for filename in all_files:\n",
        "    df = pd.read_csv(filename, index_col=None, header=0)\n",
        "\n",
        "    # Удалим дубликаты лемм внутри каждого файла\n",
        "    df_unique = df.drop_duplicates(subset='lemma')\n",
        "\n",
        "    df_merged = pd.concat([df_merged, df_unique], ignore_index=True)\n",
        "\n",
        "# Посчитаем количество уникальных появлений лемм\n",
        "word_counts = df_merged['lemma'].value_counts()\n",
        "\n",
        "# Получаем топ 100 лемм\n",
        "top_100_words_filtered = word_counts.head(100)\n",
        "\n",
        "top_100_words_filtered.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OuWgu5Vi92lu"
      },
      "outputs": [],
      "source": [
        "top_100_words_filtered.to_csv('../output/stats_tables/top_100_unique_words.csv', index=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
